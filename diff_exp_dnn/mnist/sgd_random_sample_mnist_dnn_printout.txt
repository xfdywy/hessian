##epoch:0##  loss : 0.356701/0.342518 ,   acc : 0.889900/0.894700 ,   lr : 0.100000
##epoch:0##  loss : 0.281562/0.287852 ,   acc : 0.915950/0.912200 ,   lr : 0.100000
##epoch:0##  loss : 0.207189/0.212037 ,   acc : 0.938067/0.935900 ,   lr : 0.100000
##epoch:0##  loss : 0.196089/0.202464 ,   acc : 0.940733/0.936400 ,   lr : 0.100000
##epoch:1##  loss : 0.164118/0.171519 ,   acc : 0.952867/0.948000 ,   lr : 0.100000
##epoch:1##  loss : 0.163217/0.174191 ,   acc : 0.954333/0.947200 ,   lr : 0.100000
##epoch:1##  loss : 0.164316/0.179900 ,   acc : 0.955067/0.946900 ,   lr : 0.100000
##epoch:1##  loss : 0.161296/0.177492 ,   acc : 0.957067/0.950600 ,   lr : 0.100000
##epoch:2##  loss : 0.162106/0.176908 ,   acc : 0.959083/0.953100 ,   lr : 0.100000
learning rate decrease to  0.01
##epoch:2##  loss : 0.154931/0.168665 ,   acc : 0.960933/0.953700 ,   lr : 0.010000
##epoch:2##  loss : 0.155225/0.170853 ,   acc : 0.961283/0.954000 ,   lr : 0.010000
##epoch:2##  loss : 0.155312/0.171533 ,   acc : 0.961150/0.953600 ,   lr : 0.010000
##epoch:3##  loss : 0.155505/0.171665 ,   acc : 0.961383/0.953700 ,   lr : 0.010000
##epoch:3##  loss : 0.155660/0.172438 ,   acc : 0.961567/0.953300 ,   lr : 0.010000
##epoch:3##  loss : 0.156422/0.174417 ,   acc : 0.961417/0.953900 ,   lr : 0.010000
learning rate decrease to  0.001
##epoch:3##  loss : 0.156356/0.174385 ,   acc : 0.961483/0.953400 ,   lr : 0.001000
##epoch:4##  loss : 0.156360/0.174235 ,   acc : 0.961517/0.953500 ,   lr : 0.001000
##epoch:4##  loss : 0.156364/0.174082 ,   acc : 0.961633/0.953800 ,   lr : 0.001000
##epoch:4##  loss : 0.156404/0.174137 ,   acc : 0.961583/0.953300 ,   lr : 0.001000
##epoch:4##  loss : 0.156464/0.174091 ,   acc : 0.961667/0.953900 ,   lr : 0.001000
##epoch:5##  loss : 0.156622/0.174277 ,   acc : 0.961667/0.953600 ,   lr : 0.001000
learning rate decrease to  0.0001
##epoch:5##  loss : 0.156621/0.174273 ,   acc : 0.961667/0.953600 ,   lr : 0.000100
##epoch:5##  loss : 0.156607/0.174259 ,   acc : 0.961650/0.953600 ,   lr : 0.000100
##epoch:5##  loss : 0.156624/0.174272 ,   acc : 0.961650/0.953600 ,   lr : 0.000100
##epoch:6##  loss : 0.156627/0.174285 ,   acc : 0.961667/0.953600 ,   lr : 0.000100
##epoch:6##  loss : 0.156632/0.174277 ,   acc : 0.961717/0.953600 ,   lr : 0.000100
##epoch:6##  loss : 0.156627/0.174268 ,   acc : 0.961717/0.953600 ,   lr : 0.000100
learning rate decrease to  1e-05
##epoch:6##  loss : 0.156627/0.174268 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
##epoch:7##  loss : 0.156627/0.174267 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
##epoch:7##  loss : 0.156627/0.174268 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
##epoch:7##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
##epoch:7##  loss : 0.156627/0.174268 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
##epoch:8##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000010
learning rate decrease to  1.0000000000000002e-06
##epoch:8##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:8##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:8##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:9##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:9##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:9##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:9##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:10##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:10##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
##epoch:10##  loss : 0.156627/0.174269 ,   acc : 0.961717/0.953600 ,   lr : 0.000001
learning rate decrease to  1.0000000000000002e-07
