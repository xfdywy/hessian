##epoch:0##  loss : 0.318935/0.314741 ,   acc : 0.904333/0.908400 ,   lr : 0.100000
##epoch:0##  loss : 0.257089/0.258903 ,   acc : 0.922683/0.922500 ,   lr : 0.100000
##epoch:0##  loss : 0.224755/0.228053 ,   acc : 0.933200/0.929500 ,   lr : 0.100000
##epoch:0##  loss : 0.205405/0.210236 ,   acc : 0.938817/0.936700 ,   lr : 0.100000
##epoch:1##  loss : 0.183105/0.198939 ,   acc : 0.948067/0.942200 ,   lr : 0.100000
##epoch:1##  loss : 0.162162/0.170918 ,   acc : 0.954933/0.950900 ,   lr : 0.100000
##epoch:1##  loss : 0.162908/0.172772 ,   acc : 0.955067/0.950500 ,   lr : 0.100000
##epoch:1##  loss : 0.162856/0.173393 ,   acc : 0.955833/0.951700 ,   lr : 0.100000
##epoch:2##  loss : 0.160128/0.173666 ,   acc : 0.959850/0.955000 ,   lr : 0.100000
##epoch:2##  loss : 0.160522/0.172122 ,   acc : 0.960517/0.955300 ,   lr : 0.100000
##epoch:2##  loss : 0.165389/0.179852 ,   acc : 0.960367/0.955100 ,   lr : 0.100000
learning rate decrease to  0.01
##epoch:2##  loss : 0.160586/0.174561 ,   acc : 0.961383/0.956400 ,   lr : 0.010000
##epoch:3##  loss : 0.160841/0.175174 ,   acc : 0.961900/0.956300 ,   lr : 0.010000
##epoch:3##  loss : 0.161524/0.176402 ,   acc : 0.961517/0.956700 ,   lr : 0.010000
##epoch:3##  loss : 0.162178/0.177345 ,   acc : 0.961683/0.956800 ,   lr : 0.010000
##epoch:3##  loss : 0.163009/0.177989 ,   acc : 0.961650/0.956200 ,   lr : 0.010000
##epoch:4##  loss : 0.163695/0.178511 ,   acc : 0.961933/0.956400 ,   lr : 0.010000
learning rate decrease to  0.001
##epoch:4##  loss : 0.163678/0.178578 ,   acc : 0.961850/0.956400 ,   lr : 0.001000
##epoch:4##  loss : 0.163791/0.178765 ,   acc : 0.961900/0.956400 ,   lr : 0.001000
##epoch:4##  loss : 0.163839/0.178741 ,   acc : 0.961917/0.956300 ,   lr : 0.001000
##epoch:5##  loss : 0.163906/0.178789 ,   acc : 0.961867/0.956500 ,   lr : 0.001000
##epoch:5##  loss : 0.163912/0.178819 ,   acc : 0.961967/0.956600 ,   lr : 0.001000
##epoch:5##  loss : 0.163972/0.178916 ,   acc : 0.961883/0.956300 ,   lr : 0.001000
learning rate decrease to  0.0001
