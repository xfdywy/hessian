##epoch:0##  loss : 4.404716/4.414855 ,   acc : 0.035820/0.036200 ,   lr : 0.100000
##epoch:0##  loss : 4.174203/4.188679 ,   acc : 0.058600/0.059400 ,   lr : 0.100000
##epoch:0##  loss : 4.135773/4.157407 ,   acc : 0.062400/0.064400 ,   lr : 0.100000
##epoch:0##  loss : 3.980078/4.003507 ,   acc : 0.087060/0.085300 ,   lr : 0.100000
##epoch:1##  loss : 3.890860/3.934127 ,   acc : 0.098360/0.093400 ,   lr : 0.100000
##epoch:1##  loss : 3.796044/3.852394 ,   acc : 0.111520/0.106600 ,   lr : 0.100000
##epoch:1##  loss : 3.863641/3.928861 ,   acc : 0.112900/0.108300 ,   lr : 0.100000
##epoch:1##  loss : 3.715526/3.782471 ,   acc : 0.135480/0.129900 ,   lr : 0.100000
##epoch:2##  loss : 3.657603/3.736815 ,   acc : 0.146440/0.138700 ,   lr : 0.100000
##epoch:2##  loss : 3.721120/3.813289 ,   acc : 0.140240/0.128300 ,   lr : 0.100000
##epoch:2##  loss : 3.816004/3.927253 ,   acc : 0.125140/0.111700 ,   lr : 0.100000
learning rate decrease to  0.01
##epoch:2##  loss : 3.522758/3.652374 ,   acc : 0.180280/0.161800 ,   lr : 0.010000
##epoch:3##  loss : 3.504402/3.645749 ,   acc : 0.186400/0.169300 ,   lr : 0.010000
##epoch:3##  loss : 3.499508/3.644120 ,   acc : 0.186720/0.164700 ,   lr : 0.010000
##epoch:3##  loss : 3.499328/3.646932 ,   acc : 0.187960/0.166500 ,   lr : 0.010000
##epoch:3##  loss : 3.500536/3.654839 ,   acc : 0.189520/0.165900 ,   lr : 0.010000
##epoch:4##  loss : 3.483413/3.640889 ,   acc : 0.192340/0.169100 ,   lr : 0.010000
##epoch:4##  loss : 3.485258/3.650919 ,   acc : 0.193600/0.171100 ,   lr : 0.010000
##epoch:4##  loss : 3.482886/3.649127 ,   acc : 0.191860/0.165400 ,   lr : 0.010000
##epoch:4##  loss : 3.493960/3.661239 ,   acc : 0.194020/0.170000 ,   lr : 0.010000
learning rate decrease to  0.001
##epoch:5##  loss : 3.469073/3.636155 ,   acc : 0.198640/0.172500 ,   lr : 0.001000
##epoch:5##  loss : 3.466403/3.634881 ,   acc : 0.198380/0.171800 ,   lr : 0.001000
##epoch:5##  loss : 3.465401/3.633931 ,   acc : 0.198980/0.170900 ,   lr : 0.001000
##epoch:5##  loss : 3.462729/3.632198 ,   acc : 0.200640/0.173400 ,   lr : 0.001000
##epoch:6##  loss : 3.463033/3.632592 ,   acc : 0.200400/0.170900 ,   lr : 0.001000
##epoch:6##  loss : 3.461928/3.632679 ,   acc : 0.199620/0.171700 ,   lr : 0.001000
##epoch:6##  loss : 3.461984/3.633966 ,   acc : 0.199620/0.173000 ,   lr : 0.001000
##epoch:6##  loss : 3.463816/3.636091 ,   acc : 0.200000/0.171300 ,   lr : 0.001000
learning rate decrease to  0.0001
##epoch:7##  loss : 3.463068/3.635648 ,   acc : 0.199920/0.170800 ,   lr : 0.000100
##epoch:7##  loss : 3.462636/3.635366 ,   acc : 0.200100/0.171400 ,   lr : 0.000100
##epoch:7##  loss : 3.462102/3.634806 ,   acc : 0.200120/0.171100 ,   lr : 0.000100
##epoch:7##  loss : 3.462014/3.634601 ,   acc : 0.200460/0.171600 ,   lr : 0.000100
##epoch:8##  loss : 3.461232/3.633714 ,   acc : 0.200320/0.171600 ,   lr : 0.000100
##epoch:8##  loss : 3.461024/3.633626 ,   acc : 0.200400/0.171600 ,   lr : 0.000100
##epoch:8##  loss : 3.460717/3.633228 ,   acc : 0.200640/0.171600 ,   lr : 0.000100
##epoch:8##  loss : 3.460369/3.632946 ,   acc : 0.200820/0.171400 ,   lr : 0.000100
##epoch:9##  loss : 3.460210/3.632616 ,   acc : 0.200620/0.172300 ,   lr : 0.000100
##epoch:9##  loss : 3.460146/3.632584 ,   acc : 0.200620/0.172100 ,   lr : 0.000100
##epoch:9##  loss : 3.460169/3.632867 ,   acc : 0.200700/0.171700 ,   lr : 0.000100
##epoch:9##  loss : 3.460311/3.633176 ,   acc : 0.200940/0.171900 ,   lr : 0.000100
learning rate decrease to  1e-05
##epoch:10##  loss : 3.460349/3.633196 ,   acc : 0.200820/0.172100 ,   lr : 0.000010
##epoch:10##  loss : 3.460365/3.633229 ,   acc : 0.200840/0.172100 ,   lr : 0.000010
##epoch:10##  loss : 3.460363/3.633219 ,   acc : 0.200860/0.172400 ,   lr : 0.000010
##epoch:10##  loss : 3.460275/3.633141 ,   acc : 0.200820/0.172300 ,   lr : 0.000010
##epoch:11##  loss : 3.460278/3.633145 ,   acc : 0.200860/0.172400 ,   lr : 0.000010
##epoch:11##  loss : 3.460294/3.633183 ,   acc : 0.201000/0.172100 ,   lr : 0.000010
##epoch:11##  loss : 3.460258/3.633140 ,   acc : 0.200860/0.172400 ,   lr : 0.000010
##epoch:11##  loss : 3.460259/3.633131 ,   acc : 0.200820/0.172400 ,   lr : 0.000010
##epoch:12##  loss : 3.460241/3.633156 ,   acc : 0.200920/0.172100 ,   lr : 0.000010
##epoch:12##  loss : 3.460215/3.633143 ,   acc : 0.200780/0.172200 ,   lr : 0.000010
##epoch:12##  loss : 3.460179/3.633116 ,   acc : 0.200820/0.172300 ,   lr : 0.000010
##epoch:12##  loss : 3.460181/3.633110 ,   acc : 0.200780/0.172400 ,   lr : 0.000010
##epoch:13##  loss : 3.460144/3.633088 ,   acc : 0.200900/0.172400 ,   lr : 0.000010
##epoch:13##  loss : 3.460143/3.633113 ,   acc : 0.200860/0.172200 ,   lr : 0.000010
##epoch:13##  loss : 3.460094/3.633075 ,   acc : 0.200900/0.172300 ,   lr : 0.000010
##epoch:13##  loss : 3.460077/3.633090 ,   acc : 0.200780/0.172100 ,   lr : 0.000010
##epoch:14##  loss : 3.460003/3.633000 ,   acc : 0.200820/0.172300 ,   lr : 0.000010
##epoch:14##  loss : 3.459982/3.632959 ,   acc : 0.200920/0.172200 ,   lr : 0.000010
##epoch:14##  loss : 3.459969/3.632963 ,   acc : 0.200820/0.172400 ,   lr : 0.000010
##epoch:14##  loss : 3.459889/3.632905 ,   acc : 0.200880/0.172400 ,   lr : 0.000010
##epoch:15##  loss : 3.459857/3.632884 ,   acc : 0.200840/0.172300 ,   lr : 0.000010
##epoch:15##  loss : 3.459802/3.632830 ,   acc : 0.200860/0.172400 ,   lr : 0.000010
##epoch:15##  loss : 3.459801/3.632832 ,   acc : 0.200860/0.172300 ,   lr : 0.000010
##epoch:15##  loss : 3.459807/3.632837 ,   acc : 0.200960/0.172400 ,   lr : 0.000010
##epoch:16##  loss : 3.459754/3.632802 ,   acc : 0.200880/0.172500 ,   lr : 0.000010
##epoch:16##  loss : 3.459738/3.632784 ,   acc : 0.200900/0.172500 ,   lr : 0.000010
##epoch:16##  loss : 3.459723/3.632782 ,   acc : 0.201000/0.172500 ,   lr : 0.000010
##epoch:16##  loss : 3.459723/3.632784 ,   acc : 0.201040/0.172400 ,   lr : 0.000010
##epoch:17##  loss : 3.459744/3.632826 ,   acc : 0.201000/0.172400 ,   lr : 0.000010
learning rate decrease to  1.0000000000000002e-06
##epoch:17##  loss : 3.459742/3.632822 ,   acc : 0.201000/0.172400 ,   lr : 0.000001
##epoch:17##  loss : 3.459738/3.632821 ,   acc : 0.200980/0.172400 ,   lr : 0.000001
##epoch:17##  loss : 3.459735/3.632818 ,   acc : 0.200980/0.172400 ,   lr : 0.000001
##epoch:18##  loss : 3.459731/3.632815 ,   acc : 0.200980/0.172400 ,   lr : 0.000001
##epoch:18##  loss : 3.459729/3.632813 ,   acc : 0.200960/0.172400 ,   lr : 0.000001
##epoch:18##  loss : 3.459724/3.632812 ,   acc : 0.200980/0.172500 ,   lr : 0.000001
##epoch:18##  loss : 3.459723/3.632810 ,   acc : 0.200960/0.172500 ,   lr : 0.000001
##epoch:19##  loss : 3.459715/3.632806 ,   acc : 0.200940/0.172500 ,   lr : 0.000001
##epoch:19##  loss : 3.459716/3.632807 ,   acc : 0.200940/0.172500 ,   lr : 0.000001
##epoch:19##  loss : 3.459721/3.632811 ,   acc : 0.200940/0.172500 ,   lr : 0.000001
learning rate decrease to  1.0000000000000002e-07
##epoch:19##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:20##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:20##  loss : 3.459722/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:20##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:20##  loss : 3.459722/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:21##  loss : 3.459722/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-08
##epoch:21##  loss : 3.459722/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:21##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:21##  loss : 3.459722/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:22##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:22##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:22##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-09
##epoch:22##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:23##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:23##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:23##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:23##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:24##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-10
##epoch:24##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:24##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:24##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:25##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:25##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:25##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-11
##epoch:25##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:26##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:26##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:26##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:26##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:27##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-12
##epoch:27##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:27##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:27##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:28##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:28##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:28##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-13
##epoch:28##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:29##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:29##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:29##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:29##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:30##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-14
##epoch:30##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:30##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:30##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:31##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:31##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:31##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1e-15
##epoch:31##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:32##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:32##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:32##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:32##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:33##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-16
##epoch:33##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:33##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:33##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:34##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:34##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:34##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1e-17
##epoch:34##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:35##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:35##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:35##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:35##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:36##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1e-18
##epoch:36##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:36##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:36##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:37##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:37##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:37##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-19
##epoch:37##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:38##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:38##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:38##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:38##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:39##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-20
##epoch:39##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:39##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:39##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:40##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:40##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:40##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-21
##epoch:40##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:41##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:41##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:41##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:41##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:42##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1e-22
##epoch:42##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:42##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:42##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:43##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:43##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:43##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-23
##epoch:43##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:44##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:44##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:44##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:44##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:45##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000001e-24
##epoch:45##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:45##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:45##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:46##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:46##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:46##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-25
##epoch:46##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:47##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:47##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:47##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:47##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:48##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-26
##epoch:48##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:48##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:48##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:49##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:49##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:49##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-27
##epoch:49##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:50##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:50##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:50##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:50##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:51##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-28
##epoch:51##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:51##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:51##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:52##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:52##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:52##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-29
##epoch:52##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:53##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:53##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:53##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:53##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:54##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-30
##epoch:54##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:54##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:54##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:55##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:55##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:55##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-31
##epoch:55##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:56##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:56##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:56##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:56##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:57##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-32
##epoch:57##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:57##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:57##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:58##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:58##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:58##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-33
##epoch:58##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:59##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:59##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:59##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:59##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:60##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-34
##epoch:60##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:60##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:60##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:61##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:61##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:61##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-35
##epoch:61##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:62##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:62##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:62##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:62##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:63##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-36
##epoch:63##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:63##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:63##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:64##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:64##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:64##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000005e-37
##epoch:64##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:65##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:65##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:65##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:65##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:66##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000005e-38
##epoch:66##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:66##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:66##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:67##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:67##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:67##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-39
##epoch:67##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:68##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:68##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:68##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:68##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:69##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-40
##epoch:69##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:69##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:69##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:70##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:70##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:70##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-41
##epoch:70##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:71##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:71##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:71##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:71##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:72##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-42
##epoch:72##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:72##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:72##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:73##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:73##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:73##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-43
##epoch:73##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:74##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:74##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:74##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:74##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:75##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-44
##epoch:75##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:75##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:75##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:76##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:76##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:76##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-45
##epoch:76##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:77##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:77##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:77##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:77##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:78##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-46
##epoch:78##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:78##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:78##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:79##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:79##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:79##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000002e-47
##epoch:79##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:80##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:80##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:80##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:80##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:81##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-48
##epoch:81##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:81##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:81##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:82##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:82##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:82##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-49
##epoch:82##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:83##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:83##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:83##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:83##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:84##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-50
##epoch:84##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:84##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:84##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:85##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:85##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:85##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000003e-51
##epoch:85##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:86##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:86##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:86##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:86##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:87##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
learning rate decrease to  1.0000000000000004e-52
##epoch:87##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:87##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:87##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:88##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000
##epoch:88##  loss : 3.459721/3.632812 ,   acc : 0.200940/0.172500 ,   lr : 0.000000